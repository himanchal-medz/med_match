{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical mappings:  228\n",
      "Skipping Concat Logic Here!\n"
     ]
    }
   ],
   "source": [
    "    from datetime import datetime\n",
    "    import random\n",
    "    import subprocess\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import requests\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    import calendar\n",
    "    import time\n",
    "    import warnings\n",
    "    import datetime as dt\n",
    "    import time\n",
    "    import gc\n",
    "    from collections import OrderedDict\n",
    "    import math\n",
    "    from collections import Counter\n",
    "   \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    #####################################################################################################\n",
    "    ################ Directory where input file is stored and output files will be saved ################\n",
    "    #####################################################################################################\n",
    "    \n",
    "    # os.chdir('../Output/')\n",
    "    # #os.chdir('/Arun/_SelfLearn/Mapping/')\n",
    "    # print('dist_name:',dist_name)\n",
    "    # inputdata=dist_name+\"_data.csv\"\n",
    "    # outfile1=dist_name+\"_\"+\"Combined_results.csv\"\n",
    "    # outfile2=dist_name+\"_\"+\"exact_mapped.csv\"\n",
    "    # outfile3=dist_name+\"_\"+\"partial_mapped.csv\"\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #df_master = pd.read_csv('drug_master2.csv') \n",
    "    df_master = pd.read_csv('../Master Mappings/drug_master_07March.csv', encoding='ISO-8859-1') # Updated Master Data with sku for all\n",
    "    #df_distributor = pd.read_csv('distributor_data.csv') # New Distributor data to be mapped\n",
    "    df_distributor = pd.read_csv('../Datasets/Apollo_unmapped_07March.csv', encoding='ISO-8859-1') # New Distributor data to be mapped\n",
    "    #df_distributor = df_distributor[['item_code', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp']]\n",
    "    \n",
    "    # Required Schema of Distributor Data - ['item_code', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp']\n",
    "    # Appending columns if not already present, order should be maintained by distributor\n",
    "    i = 1\n",
    "    while(len(df_distributor.columns)<7):\n",
    "        new_col_name = \"new_col\" + str(i)\n",
    "        i = i+1\n",
    "        df_distributor[new_col_name] = \"\"\n",
    "    \n",
    "    df_distributor.columns = ['item_code', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp']\n",
    "    df_distributor['Master Catalogue name'] = \"\"\n",
    "    \n",
    "    #df_distributor['brand'] = df_distributor['brand'] + ' ' + df_distributor['pack']\n",
    "    \n",
    "    \n",
    "    # Handling cases where sku_brand is not present in master data\n",
    "    df_master['sku_brand'] = np.where(df_master['sku_brand'].isnull(), df_master['brand'].str.split(' ').str[0], df_master['sku_brand'])\n",
    "    \n",
    "    synonyms_dict = {'':['dt', 'sr', 'cr', 'mr', 'er', 'dr', 'pr', 'xr', 'xl', 'xt', 'pr', 'dpi', 'mdi', 'md', 'ap', 'md'],\n",
    "         '1s':['1x1','1[*]1','1tab','1x1'],\n",
    "         '2s':['2x1','1[*]2','2tab','1x2'],\n",
    "         '3s':['3x1','1[*]3','3tab','1x3'],\n",
    "         '4s':['4x1','1[*]4','4tab','1x4'],\n",
    "         '5s':['5x1','1[*]5','5tab','1x5'],\n",
    "         '6s':['6x1','1[*]6','6tab','1x6'],\n",
    "         '7s':['7x1','1[*]7','7tab','1x7'],\n",
    "         '8s':['8x1','1[*]8','8tab','1x8'],\n",
    "         '9s':['9x1','1[*]9','9tab','1x9'],\n",
    "         '10s':['10x1','1[*]10','10tab','1x10'],\n",
    "         '120s':['120x1', '1[*]120','120tab','1x120'],\n",
    "         '150s':['150x1', '1[*]150','150tab','1x150'],\n",
    "         '200s':['200x1', '1[*]200','200tab','1x200'],\n",
    "         '15s':['15x1','1[*]15','15tab','1x15'],\n",
    "         '20s':['20x1','1[*]20','20tab','1x20'],\n",
    "         '25s':['25x1','1[*]25','25tab','1x25'],\n",
    "         '30s':['30x1','1[*]30','30tab','1x30'],\n",
    "         '35s':['35x1','1[*]35','35tab','1x35'],\n",
    "         '40s':['40x1','1[*]40','40tab','1x40'],\n",
    "         '50s':['50x1','1[*]50','50tab','1x50'],\n",
    "         '60s':['60x1','1[*]60','60tab','1x60'],\n",
    "         '70s':['70x1','1[*]70','70tab','1x70'],\n",
    "         '80s':['80x1','1[*]80','80tab','1x80'],\n",
    "         '90s':['90x1','1[*]90','90tab','1x90'],\n",
    "         'adult':['adults'],\n",
    "         'aloe vera':['aloe','aloe vera','aloevera','elovera','alovera'],\n",
    "         'vera':['vera vera'],\n",
    "         'amla':['aamla'],\n",
    "         'amritarishta':['amritarist','amritarisht','amritarishta','amritarista'],\n",
    "         'amrutanjan':['amritanjan'],\n",
    "         'anti':['anit'],\n",
    "         'arjunarishta':['arjunarishta','arjunarista','arjunaristha'],\n",
    "         'ashokarishta':['ashokarishta','ashokarista','ashokarisht','ashokarist'],\n",
    "         'baby':['infant'],\n",
    "         'soap':['bar'],\n",
    "         'brush':['toothbrush','tooth brush'],\n",
    "         'chocolate':['choclate','choco'],\n",
    "         'cleansing':['cleaning'],\n",
    "         'cream':['creme','creem','crema'],\n",
    "         'culture':['cullture'],\n",
    "         'dental gel':['oral gel'],\n",
    "         'diapers':['diaper'],\n",
    "         'diskette':['diskettes'],\n",
    "         'drops':['drop', 'drps'],\n",
    "         'expectorant':['expt'],\n",
    "         'eye drops':['opthalmic solution','eye drop', 'e/d'],\n",
    "         'eye':['eyes','opthalmic'],\n",
    "         'eye/ear':['e/e'],\n",
    "         'injection':['inj', 'inj.', 'inj.s', 'injs', 'injections', 'injtion', 'inje'],\n",
    "         'janma':['janam'],\n",
    "         'gel':['jelly'],\n",
    "         'liquid':['liq','fluid'],\n",
    "         'lotion':['moist'],\n",
    "         'lozenges':['lozenge'],\n",
    "         'md':['mdi'],\n",
    "         'mixtard':['mixact','mistard'],\n",
    "         'moisturiser':['moisturizer'],\n",
    "         'moisturising':['moistarizing','moistursing'],\n",
    "         'moov':['move'],\n",
    "         'mother':['mom'],\n",
    "         'ointment':['oint'],\n",
    "         'paediatric':['paed', 'ped', 'junior', 'kid', 'kids', 'child', 'kidzo', 'pediatric', 'peadiatric', 'peditric'], \n",
    "         'paper':['strip'],\n",
    "         'penfill':['pen','penfill','augpen','flexpen','flexpens'],\n",
    "         'pessaries':['pessary'],\n",
    "         'plus':[\"[+]\"],\n",
    "         'protein':['protien','portien'],\n",
    "         'readymix':['readimix', 'ready mix'],\n",
    "         'refill':['refil','rifill','rifil'],\n",
    "         'wash':['rinse'],\n",
    "         'capsule':['rotacap', 'rotacaps', 'transcap', 'transcaps', 'cap', 'caps', 'cap.', 'capsules', 'capsule.', 'rosycap', 'instacap', 'instacaps'],\n",
    "         'skin':['derma'],\n",
    "         'sg':['soft gels','soft gelatin'],\n",
    "         'solution':['soln', 'soln.'],\n",
    "         'spray':['spry'],\n",
    "         'sf':['sugar free'],\n",
    "         'suppository':['suppositories', 'supositories', 'supository'],\n",
    "         'suspension':['susp', 'susp.', 'suspp', 'susppension', 'suspention'],\n",
    "         'syrup':['syp', 'syp.', 'syrp', 'syr', 'syp.s', 'syps', 'syrups'],\n",
    "         'tablet':['tab', 'tabs', 'tablets', 'tab.', 'tablet.', 'tab.s', 'tablt', 'chewtab'],\n",
    "         'tel':['tail'],\n",
    "         'thermometer':['thermometre','therometer'],\n",
    "         'toothpaste':['paste','tooth paste', 'tooth toothpaste'],\n",
    "         'vaccine':['vax', 'vac'],\n",
    "         'vanilla':['vanila'],\n",
    "         '1kg':['1000gm', '1000g'],\n",
    "         '1000mg':['1gm', '1g'],\n",
    "         '2gm':['2g'],\n",
    "         '3gm':['3g'],\n",
    "         '4gm':['4g'],\n",
    "         '5gm':['5g'],\n",
    "         '10gm':['10g'],\n",
    "         '100gm':['100g'],\n",
    "         '1ml':['1x1ml'],\n",
    "         '2ml':['1x2ml'],\n",
    "         '3ml':['1x3ml'],\n",
    "         '4ml':['1x4ml'],\n",
    "         '5ml':['1x5ml'],\n",
    "         '6ml':['1x6ml'],\n",
    "         '7ml':['1x7ml'],\n",
    "         '8ml':['1x8ml'],\n",
    "         '9ml':['1x9ml'],\n",
    "         '10ml':['1x10ml'],\n",
    "         '15ml':['1x15ml'],\n",
    "         '20ml':['1x20ml'],\n",
    "         '25ml':['1x25ml'],\n",
    "         '30ml':['1x30ml'],\n",
    "         '35ml':['1x35ml'],\n",
    "         '40ml':['1x40ml'],\n",
    "         '45ml':['1x45ml'],\n",
    "         '50ml':['1x50ml'],\n",
    "         '60ml':['1x60ml'],\n",
    "         '70ml':['1x70ml'],\n",
    "         '80ml':['1x80ml'],\n",
    "         '90ml':['1x90ml'],\n",
    "         '100ml':['1x100ml'],\n",
    "         '200ml':['1x200ml'],\n",
    "         '300ml':['1x300ml'],\n",
    "         '400ml':['1x400ml'],\n",
    "         '500ml':['1x500ml'],\n",
    "         '1mg':['1x1mg'],\n",
    "         '2mg':['1x2mg'],\n",
    "         '3mg':['1x3mg'],\n",
    "         '4mg':['1x4mg'],\n",
    "         '5mg':['1x5mg'],\n",
    "         '6mg':['1x6mg'],\n",
    "         '7mg':['1x7mg'],\n",
    "         '8mg':['1x8mg'],\n",
    "         '9mg':['1x9mg'],\n",
    "         '10mg':['1x10mg'],\n",
    "         '15mg':['1x15mg'],\n",
    "         '20mg':['1x20mg'],\n",
    "         '25mg':['1x25mg'],\n",
    "         '30mg':['1x30mg'],\n",
    "         '35mg':['1x35mg'],\n",
    "         '40mg':['1x40mg'],\n",
    "         '45mg':['1x45mg'],\n",
    "         '50mg':['1x50mg'],\n",
    "         '60mg':['1x60mg'],\n",
    "         '70mg':['1x70mg'],\n",
    "         '80mg':['1x80mg'],\n",
    "         '90mg':['1x90mg'],\n",
    "         '100mg':['1x100mg'],\n",
    "         '200mg':['1x200mg'],\n",
    "         '300mg':['1x300mg'],\n",
    "         '400mg':['1x400mg'],\n",
    "         '500mg':['1x500mg'],\n",
    "         '1gm':['1x1gm'],\n",
    "         '2gm':['1x2gm'],\n",
    "         '3gm':['1x3gm'],\n",
    "         '4gm':['1x4gm'],\n",
    "         '5gm':['1x5gm'],\n",
    "         '6gm':['1x6gm'],\n",
    "         '7gm':['1x7gm'],\n",
    "         '8gm':['1x8gm'],\n",
    "         '9gm':['1x9gm'],\n",
    "         '10gm':['1x10gm'],\n",
    "         '15gm':['1x15gm'],\n",
    "         '20gm':['1x20gm'],\n",
    "         '25gm':['1x25gm'],\n",
    "         '30gm':['1x30gm'],\n",
    "         '35gm':['1x35gm'],\n",
    "         '40gm':['1x40gm'],\n",
    "         '45gm':['1x45gm'],\n",
    "         '50gm':['1x50gm'],\n",
    "         '60gm':['1x60gm'],\n",
    "         '70gm':['1x70gm'],\n",
    "         '80gm':['1x80gm'],\n",
    "         '90gm':['1x90gm'],\n",
    "         '100gm':['1x100gm'],\n",
    "         '200gm':['1x200gm'],\n",
    "         '300gm':['1x300gm'],\n",
    "         '400gm':['1x400gm'],\n",
    "         '500gm':['1x500gm'],\n",
    "         '1g':['1x1g'],\n",
    "         '2g':['1x2g'],\n",
    "         '3g':['1x3g'],\n",
    "         '4g':['1x4g'],\n",
    "         '5g':['1x5g'],\n",
    "         '6g':['1x6g'],\n",
    "         '7g':['1x7g'],\n",
    "         '8g':['1x8g'],\n",
    "         '9g':['1x9g'],\n",
    "         '10g':['1x10g'],\n",
    "         '15g':['1x15g'],\n",
    "         '20g':['1x20g'],\n",
    "         '25g':['1x25g'],\n",
    "         '30g':['1x30g'],\n",
    "         '35g':['1x35g'],\n",
    "         '40g':['1x40g'],\n",
    "         '45g':['1x45g'],\n",
    "         '50g':['1x50g'],\n",
    "         '60g':['1x60g'],\n",
    "         '70g':['1x70g'],\n",
    "         '80g':['1x80g'],\n",
    "         '90g':['1x90g'],\n",
    "         '100g':['1x100g'],\n",
    "         '200g':['1x200g'],\n",
    "         '300g':['1x300g'],\n",
    "         '400g':['1x400g'],\n",
    "         '500g':['1x500g']\n",
    "    }\n",
    "\n",
    "    #### Historical Mapping\n",
    "    historical_map_1 = pd.read_csv('../historical_mapping/hist_map_latest.csv')\n",
    "    historical_map_1 = historical_map_1[['item_code','brand_x', 'brand_y', 'drug_master_id']]\n",
    "\n",
    "    historical_map_2 = pd.read_csv('../historical_mapping/hist_map_2.csv')\n",
    "    historical_map_2 = historical_map_2[['item_code','brand_x', 'brand_y', 'drug_master_id']]\n",
    "\n",
    "    historical_map = pd.concat([historical_map_1, historical_map_2])\n",
    "\n",
    "    historical_map['brand_x'] = historical_map['brand_x'].str.lower()\n",
    "    df_distributor['brand'] = df_distributor['brand'].str.lower()\n",
    "\n",
    "    final = pd.merge(df_distributor, historical_map, how='left', left_on=['brand'],right_on=['brand_x'])\n",
    "    final_mapped = final[final['brand_y'].notnull()].reset_index(drop = True)\n",
    "    print(\"Historical mappings: \",final_mapped.shape[0])\n",
    "\n",
    "    final = final[final['brand_x'].isnull()].reset_index(drop = True)\n",
    "    final = final[['item_code_x', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp','Master Catalogue name']]\n",
    "    final = final.rename(columns = {'item_code_x':'item_code'})\n",
    "    df_distributor = final.copy()\n",
    "    \n",
    "    ####### Concat Logic New #########\n",
    "\n",
    "    # df_distributor['pack'] = df_distributor['pack'].str.lower()\n",
    "    # df_distributor['brand'] = df_distributor['brand'].str.lower()\n",
    "\n",
    "    # df_distributor['mod_pack'] = df_distributor['pack'].str.lower()\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'] + ' '\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('-', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace(',', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('^', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('#', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('[(]', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('[)]', ' ')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace('`', '')\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace(\"'\", \"\")\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace(\"%\", \"% \")\n",
    "    # df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace(\"  \", \" \")    \n",
    "        \n",
    "    # for key,values in synonyms_dict.items():\n",
    "    #     key = key + ' '\n",
    "    #     for val in values:\n",
    "    #         val = val + ' '\n",
    "    #         df_distributor['mod_pack'] = df_distributor['mod_pack'].str.replace(val, key)\n",
    "    \n",
    "    # df_1 = df_distributor[df_distributor['mod_pack'].isna()]\n",
    "    # df_2 = df_distributor[~df_distributor['mod_pack'].isna()]\n",
    "\n",
    "    # df_2['mod_pack'] = df_2['mod_pack'].str.strip()\n",
    "    # df_2['pack_exists'] = 0\n",
    "\n",
    "    # for i in range(0, len(df_2)):\n",
    "    #   if df_2.iloc[i]['mod_pack'] in df_2.iloc[i]['brand']:\n",
    "    #     df_2[\"pack_exists\"].iloc[i] = 1\n",
    "    \n",
    "    # df_3 = df_2[df_2['pack_exists']==0]\n",
    "    # df_2 = df_2[df_2['pack_exists']==1]\n",
    "    # df_3['brand'] = df_3['brand'] + ' ' + df_3['mod_pack']\n",
    "\n",
    "    # df_1.drop('mod_pack', axis=1, inplace=True)\n",
    "\n",
    "    # df_2.drop(['pack','pack_exists'], axis=1, inplace=True)\n",
    "    # df_2.rename(columns = {'mod_pack':'pack'}, inplace = True)\n",
    "    # df_2 = df_2[['item_code', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp','Master Catalogue name']]\n",
    "\n",
    "    # df_3.drop(['pack','pack_exists'], axis=1, inplace=True)\n",
    "    # df_3.rename(columns = {'mod_pack':'pack'}, inplace = True)\n",
    "    # df_3 = df_3[['item_code', 'brand', 'pack', 'manufacturer', 'catg', 'subcatg', 'mrp','Master Catalogue name']]\n",
    "\n",
    "    # pdList = [df_1, df_2, df_3]  # List of your dataframes\n",
    "    # df_distributor_new = pd.concat(pdList)\n",
    "    # df_distributor = df_distributor_new.copy()\n",
    "    \n",
    "    print(\"Skipping Concat Logic Here!\")\n",
    "\n",
    "    ################# Applying synonyms to Distributor Data ################\n",
    "    \n",
    "    df_distributor['brand'] = df_distributor['brand'].str.lower()\n",
    "    \n",
    "    df_distributor['mod_brand'] = df_distributor['brand'].str.lower()\n",
    "    #df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"  \", \" \")\n",
    "    #df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"   \", \" \")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'] + ' '\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('-', ' ')\n",
    "    #df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('.', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(',', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('^', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('#', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('[(]', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('[)]', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('`', '')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"'\", \"\")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"%\", \"% \")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"  \", \" \")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"  \", \" \")\n",
    "    \n",
    "        \n",
    "    for key,values in synonyms_dict.items():\n",
    "        key = ' ' + key + ' '\n",
    "        for val in values:\n",
    "            val = ' ' + val + ' '\n",
    "            df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(val, key)\n",
    "    \n",
    "    \n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace('*', ' ')\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"  \", \" \")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.replace(\"  \", \" \")\n",
    "    df_distributor['mod_brand'] = df_distributor['mod_brand'].str.lower().str.strip()\n",
    "    \n",
    "    # Identify type of medicine - classifiy into tablet, capsule, injection, syrup, others\n",
    "    \n",
    "    df_distributor['medicine_type'] = \"\"\n",
    "    \n",
    "    df_distributor['medicine_type'] = np.where(df_distributor['mod_brand'].str.contains('tablet', regex = False), 'tablet', df_distributor['medicine_type'])\n",
    "    df_distributor['medicine_type'] = np.where(df_distributor['mod_brand'].str.contains('capsule', regex = False), 'capsule', df_distributor['medicine_type'])\n",
    "    df_distributor['medicine_type'] = np.where(df_distributor['mod_brand'].str.contains('injection', regex = False), 'injection', df_distributor['medicine_type'])\n",
    "    df_distributor['medicine_type'] = np.where(df_distributor['mod_brand'].str.contains('syrup', regex = False), 'syrup', df_distributor['medicine_type'])\n",
    "    \n",
    "    \n",
    "    df_distributor['medicine_type'] = np.where(df_distributor['medicine_type']==\"\", 'others', df_distributor['medicine_type'])\n",
    "    \n",
    "    \n",
    "    ################# Applying synonyms to Master Data ################\n",
    "    \n",
    "    df_master['brand'] = df_master['brand'].str.lower()\n",
    "    \n",
    "    df_master['new_brand'] = df_master['brand'].str.lower()\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"  \", \" \")\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"   \", \" \")\n",
    "    df_master['new_brand'] = df_master['brand'] + ' '\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('-', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('^', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('*', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('#', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('[(]', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('[)]', ' ')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace('`', '')\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"'\", \"\")\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"%\", \"% \")\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"  \", \" \")\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"  \", \" \")\n",
    "    \n",
    "    for key,values in synonyms_dict.items():\n",
    "        key = ' ' + key + ' '\n",
    "        for val in values:\n",
    "            val = ' ' + val + ' '\n",
    "            df_master['new_brand'] = df_master['new_brand'].str.replace(val, key)\n",
    "    \n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"  \", \" \")\n",
    "    df_master['new_brand'] = df_master['new_brand'].str.replace(\"  \", \" \")\n",
    "    \n",
    "    df_master['sku_brand'] = df_master['sku_brand'].str.lower().str.strip()\n",
    "    df_master['sku_brand'] = df_master['sku_brand'].str.replace(\"  \", \" \")\n",
    "    df_master['sku_brand'] = df_master['sku_brand'].str.replace(\"  \", \" \")\n",
    "    \n",
    "    # Identify type of medicine - classifiy into tablet, capsule, injection, syrup, others\n",
    "    \n",
    "    df_master['medicine_type'] = \"\"\n",
    "    \n",
    "    df_master['medicine_type'] = np.where(df_master['new_brand'].str.contains('tablet', regex = False), 'tablet', df_master['medicine_type'])\n",
    "    df_master['medicine_type'] = np.where(df_master['new_brand'].str.contains('capsule', regex = False), 'capsule', df_master['medicine_type'])\n",
    "    df_master['medicine_type'] = np.where(df_master['new_brand'].str.contains('injection', regex = False), 'injection', df_master['medicine_type'])\n",
    "    df_master['medicine_type'] = np.where(df_master['new_brand'].str.contains('syrup', regex = False), 'syrup', df_master['medicine_type'])\n",
    "    \n",
    "    df_master['medicine_type'] = np.where(df_master['medicine_type']==\"\", 'others', df_master['medicine_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>category_c1</th>\n",
       "      <th>sku_brand</th>\n",
       "      <th>new_brand</th>\n",
       "      <th>medicine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, brand, category_c1, sku_brand, new_brand, medicine_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_master[df_master['sku_brand']=='TBD']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>category_c1</th>\n",
       "      <th>sku_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1 2 3 100MG TABLET 4S</td>\n",
       "      <td>RX</td>\n",
       "      <td>1 2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>1 2 3 25MG TABLET 5S</td>\n",
       "      <td>RX</td>\n",
       "      <td>1 2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>1 2 3 50MG TABLET 4S</td>\n",
       "      <td>RX</td>\n",
       "      <td>1 2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>1 AL AX 5MG/75MG CAPSULE 10S</td>\n",
       "      <td>RX</td>\n",
       "      <td>1 AL AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100006</td>\n",
       "      <td>1 AL MAX 5MG/10MG TABLET 10S</td>\n",
       "      <td>RX</td>\n",
       "      <td>1 AL Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380873</th>\n",
       "      <td>677490</td>\n",
       "      <td>MAXGALIN 75MG CAPSULE 15S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380874</th>\n",
       "      <td>677491</td>\n",
       "      <td>GLUXIT TRIO 10/100/1000 TABLET 15S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380875</th>\n",
       "      <td>677492</td>\n",
       "      <td>CILAHEART 5MG TABLET 15S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380876</th>\n",
       "      <td>677493</td>\n",
       "      <td>MFG 1 TABLET 10S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380877</th>\n",
       "      <td>677494</td>\n",
       "      <td>ZENACE P TABLET 10S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380878 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                               brand category_c1 sku_brand\n",
       "0       100002               1 2 3 100MG TABLET 4S          RX     1 2 3\n",
       "1       100003                1 2 3 25MG TABLET 5S          RX     1 2 3\n",
       "2       100004                1 2 3 50MG TABLET 4S          RX     1 2 3\n",
       "3       100005        1 AL AX 5MG/75MG CAPSULE 10S          RX   1 AL AX\n",
       "4       100006        1 AL MAX 5MG/10MG TABLET 10S          RX  1 AL Max\n",
       "...        ...                                 ...         ...       ...\n",
       "380873  677490           MAXGALIN 75MG CAPSULE 15S         NaN       NaN\n",
       "380874  677491  GLUXIT TRIO 10/100/1000 TABLET 15S         NaN       NaN\n",
       "380875  677492            CILAHEART 5MG TABLET 15S         NaN       NaN\n",
       "380876  677493                    MFG 1 TABLET 10S         NaN       NaN\n",
       "380877  677494                 ZENACE P TABLET 10S         NaN       NaN\n",
       "\n",
       "[380878 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = pd.read_csv('../Master Mappings/drug_master_07March.csv', encoding='ISO-8859-1')\n",
    "df_master\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
